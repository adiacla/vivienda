{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "167f5e81",
      "metadata": {
        "id": "167f5e81"
      },
      "source": [
        "# Examen Práctico: Clasificación de dígitos con Redes Neuronales Densas (Keras)\n",
        "\n",
        "**Instrucciones generales**:\n",
        "\n",
        "- Trabaja en este cuaderno y **completa únicamente las celdas de código** indicadas (no borres las celdas de enunciado).\n",
        "- Este examen pide que implementes un clasificador **multiclase** usando **redes densas** (no usar convoluciones).\n",
        "- Aunque los CNNs suelen rendir mejor en imágenes, **NO** usarás convoluciones aquí (esto es parte del enunciado).\n",
        "- Usa `TensorFlow / Keras` para construir, entrenar y evaluar el modelo.\n",
        "- Anota tus respuestas y observaciones donde se indique.\n",
        "\n",
        "![](https://www.tensorflow.org/static/datasets/overview_files/output_DpE2FD56cSQR_1.png)\n",
        "---\n",
        "\n",
        "**Formato del examen**: cada sección contiene\n",
        "1. Un enunciado (qué debes hacer), con **pistas** y la forma esperada de los datos.\n",
        "2. Una celda de código vacía donde debes implementar la solución.\n",
        "\n",
        "Al final debes entregar el cuaderno con las celdas completadas y una breve conclusión (máx. 300 palabras) sobre por qué un CNN funcionaría mejor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672c6184",
      "metadata": {
        "id": "672c6184"
      },
      "source": [
        "## Sección 1 — Carga de librerías y comprobación de versión\n",
        "\n",
        "**Objetivo**: Importar las librerías necesarias y comprobar la versión de Python/TensorFlow.\n",
        "\n",
        "**Debes hacer**:\n",
        "- Importar `numpy`, `matplotlib.pyplot`, `tensorflow` (alias `tf`) y `sklearn.metrics` (para reporte y matriz de confusión).\n",
        "- Mostrar `python --version` o `sys.version` y `tf.__version__`.\n",
        "\n",
        "**Pista**: usa `from tensorflow import keras` y `from tensorflow.keras.utils import to_categorical`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b442bdd",
      "metadata": {
        "id": "8b442bdd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# de Version de Tensorflow y si usa GPU\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "id": "lgVSbb7tQSgV"
      },
      "id": "lgVSbb7tQSgV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1ca05c00",
      "metadata": {
        "id": "1ca05c00"
      },
      "source": [
        "## Sección 2 — Carga del dataset\n",
        "\n",
        "**Objetivo**: Cargar el dataset `mnist` de `tf.keras.datasets`.\n",
        "\n",
        "**Debes hacer**:\n",
        "- Cargar `x_train, y_train, x_test, y_test` usando `tf.keras.datasets.mnist.load_data()`.\n",
        "- Mostrar las formas de los arrays y un resumen de los valores (mínimo, máximo) de `x_train` y `y_train`.\n",
        "\n",
        "**Forma esperada**:\n",
        "- `x_train` → (60000, 28, 28)\n",
        "- `y_train` → (60000,)\n",
        "\n",
        "**Pista**: imprime `x_train.shape, y_train.shape, x_train.min(), x_train.max()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e5c4c6b",
      "metadata": {
        "id": "6e5c4c6b"
      },
      "outputs": [],
      "source": [
        "#Cargue de datos tfds.load()\n",
        "datos, metadatos = tfds.load('mnist', as_supervised=True, with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar la vriable datos\n"
      ],
      "metadata": {
        "id": "k2p4xfsaVHMD"
      },
      "id": "k2p4xfsaVHMD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar la vriable metadatos\n"
      ],
      "metadata": {
        "id": "2ONrTTieVQu1"
      },
      "id": "2ONrTTieVQu1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"green\"> **Analisis**: Que tiene esa variable? </font>"
      ],
      "metadata": {
        "id": "Y5FAJ3c5Vhl2"
      },
      "id": "Y5FAJ3c5Vhl2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Visualización de una imagen en MNIST**\n",
        "\n",
        "Obtén el conjunto de **entrenamiento **del dataset mnist.\n",
        "\n",
        "Selecciona la primera imagen y su etiqueta usando .take(1).\n",
        "\n",
        "Convierte la imagen a numpy y guarda la etiqueta en una variable.\n",
        "\n",
        "**Imprime en pantalla:**\n",
        "\n",
        "La etiqueta de la imagen.\n",
        "\n",
        "La forma de la imagen.\n",
        "\n",
        "La primera fila de la matriz de píxeles.\n",
        "\n",
        "Muestra la imagen en blanco y negro usando matplotlib.pyplot.imshow() con cmap=plt.cm.binary.\n",
        "\n",
        "*Forma esperada:*\n",
        "\n",
        "La etiqueta debe ser un número entre 0–9.\n",
        "\n",
        "La forma de la imagen debe ser (28, 28).."
      ],
      "metadata": {
        "id": "Lof2bDCHYBGJ"
      },
      "id": "Lof2bDCHYBGJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el conjunto de entrenamiento\n",
        "\n",
        "\n",
        "# Tomar el primer elemento (imagen, etiqueta)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DjH5_aTvWmKP"
      },
      "id": "DjH5_aTvWmKP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**El objeto datos_entrenamiento es un tf.data.Dataset**\n",
        "\n",
        "Para conocer las dimensiones de las imágenes y etiquetas, debemos agrupar el dataset en lotes y luego inspeccionarlos.\n",
        "\n",
        "Agrupa el dataset de entrenamiento en lotes de tamaño 32 usando .batch(32).\n",
        "\n",
        "Toma un solo batch con .take(1).\n",
        "\n",
        "**Imprime en pantalla:**\n",
        "\n",
        "La forma del batch de imágenes.\n",
        "\n",
        "La forma del batch de etiquetas.\n",
        "\n",
        "**Forma esperada:**\n",
        "\n",
        "Imágenes → (32, 28, 28)\n",
        "\n",
        "Etiquetas → (32,)\n",
        "![](https://raw.githubusercontent.com/adiacla/bigdata/refs/heads/master/batch32.jpg)\n"
      ],
      "metadata": {
        "id": "DS9EWrXJcLSa"
      },
      "id": "DS9EWrXJcLSa"
    },
    {
      "cell_type": "code",
      "source": [
        "# Para ver un batch(32) solo de ejemplo:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dcC4LhLgb_Hq"
      },
      "id": "dcC4LhLgb_Hq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f5ec944e",
      "metadata": {
        "id": "f5ec944e"
      },
      "source": [
        "## Sección 3 — Preprocesamiento\n",
        "\n",
        "**Objetivo**: Preprocesar los datos para una red densa.\n",
        "\n",
        "Vamos a crear las variables con datos_entrenamiento y datos_pruebas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c9d5629",
      "metadata": {
        "id": "9c9d5629"
      },
      "outputs": [],
      "source": [
        "# Definir datasets de entrenamiento y prueba\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cantidad de ejemplos en los conjuntos de datos**\n",
        "\n",
        "El objeto metadatos que devuelve tfds.load() contiene información sobre los subconjuntos del dataset.\n",
        "\n",
        "Calcula:\n",
        "\n",
        "- Obtén el número total de ejemplos en el conjunto de entrenamiento (train).\n",
        "\n",
        "- Obtén el número total de ejemplos en el conjunto de prueba (test).\n",
        "\n",
        "Guarda esos valores en las variables:"
      ],
      "metadata": {
        "id": "iq2oY8up-WGR"
      },
      "id": "iq2oY8up-WGR"
    },
    {
      "cell_type": "code",
      "source": [
        "#Número de ejemplos\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5cDufFf8-XUz"
      },
      "id": "5cDufFf8-XUz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalización del dataset**\n",
        "\n",
        "Las imágenes en MNIST tienen valores de píxeles entre 0 y 255. Antes de entrenar una red neuronal es recomendable escalar estos valores al rango [0,1].\n",
        "\n",
        "Define una función llamada normalizar(imagenes, etiquetas) que:\n",
        "\n",
        "- Convierta las imágenes a tipo tf.float32.\n",
        "\n",
        "- Divida cada valor de píxel entre 255.\n",
        "\n",
        "- Devuelva (imagenes, etiquetas).\n",
        "\n",
        "- Aplica esta función al dataset de entrenamiento y al de pruebas usando .map().\n",
        "\n",
        "- Comprueba que los datos fueron transformados correctamente tomando un ejemplo del dataset y mostrando sus valores mínimo y máximo.\n",
        "\n",
        "**Pista:**\n",
        "\n",
        "- Usa tf.cast() para convertir el tipo de datos.\n",
        "\n",
        "Recuerda que .map() aplica la transformación a cada elemento del dataset.\n",
        "\n",
        "Forma esperada: los valores de los píxeles deben estar entre 0.0 y 1.0."
      ],
      "metadata": {
        "id": "WUu4dtV0ddH8"
      },
      "id": "WUu4dtV0ddH8"
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcion de normalizacion para los datos (Pasar valor de los pixeles de 0-255 a 0-1)\n",
        "# Normalización\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w71pM6gLZRFE"
      },
      "id": "w71pM6gLZRFE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preparación de los datasets en TensorFlow**\n",
        "\n",
        "Para entrenar un modelo de Deep Learning de forma eficiente, es necesario preparar los datos con un pipeline que incluya normalización, barajado y creación de lotes.\n",
        "\n",
        "Define una función normalizar que convierta los valores de las imágenes a flotantes entre 0 y 1.\n",
        "\n",
        "Recuerda que los datos de las imágenes suelen venir entre 0 y 255.\n",
        "\n",
        "La función debe recibir (x, y) y retornar (x_normalizado, y).\n",
        "\n",
        "Declara la constante TAMANO_LOTE con valor 32.\n",
        "\n",
        "**Prepara el conjunto de *datos_entrenamiento* aplicando en orden:**\n",
        "\n",
        ".map(normalizar)\n",
        "\n",
        ".cache()\n",
        "\n",
        ".shuffle(num_datos_entrenamiento) usando como buffer el total de ejemplos.\n",
        "\n",
        ".batch(TAMANO_LOTE)\n",
        "\n",
        ".repeat() para poder iterar en varias épocas.\n",
        "\n",
        "**Prepara el conjunto de *datos_pruebas* aplicando en orden:**\n",
        "\n",
        ".map(normalizar)\n",
        "\n",
        ".cache()\n",
        "\n",
        ".batch(TAMANO_LOTE)\n",
        "\n",
        "No uses shuffle() ni repeat() en pruebas."
      ],
      "metadata": {
        "id": "tEasJPuyOOEs"
      },
      "id": "tEasJPuyOOEs"
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar datasets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o6uNza0vOOSz"
      },
      "id": "o6uNza0vOOSz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimización del dataset con caché**\n",
        "\n",
        "Una forma de acelerar el entrenamiento en TensorFlow es usar .cache() sobre el dataset. Esto guarda los datos en memoria después de la primera lectura, evitando tener que cargarlos del disco en cada época.\n",
        "\n",
        "- Aplica .cache() al dataset de entrenamiento (datos_entrenamiento).\n",
        "\n",
        "- Aplica también .cache() al dataset de pruebas (datos_pruebas).\n",
        "\n",
        "Explica brevemente en un comentario por qué usar caché puede mejorar la velocidad de entrenamiento.\n",
        "\n",
        "**Pista: **.cache() se aplica directamente sobre el objeto tf.data.Dataset."
      ],
      "metadata": {
        "id": "kDtnDniUd16e"
      },
      "id": "kDtnDniUd16e"
    },
    {
      "cell_type": "code",
      "source": [
        "#Agregar a cache (usar memoria en lugar de disco, entrenamiento mas rapido)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YMG-z7usd1Jt"
      },
      "id": "YMG-z7usd1Jt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definición de clases en MNIST**\n",
        "\n",
        "El dataset MNIST contiene 10 clases que corresponden a los dígitos escritos a mano: del 0 al 9.\n",
        "\n",
        "Define una lista llamada clases que contenga las etiquetas de cada dígito como cadenas de texto.\n",
        "\n",
        "Esta lista se usará más adelante para mostrar el nombre de la clase debajo de cada imagen al graficar."
      ],
      "metadata": {
        "id": "THS2CRvavp8j"
      },
      "id": "THS2CRvavp8j"
    },
    {
      "cell_type": "code",
      "source": [
        "#Ejecute esta celda\n",
        "clases = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]"
      ],
      "metadata": {
        "id": "ysaOlb6NvqFy"
      },
      "id": "ysaOlb6NvqFy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualización de ejemplos de MNIST**\n",
        "\n",
        "El dataset MNIST contiene imágenes de dígitos escritos a mano. Para comprobar que la carga y preprocesamiento de datos es correcto, es útil visualizar algunos ejemplos.\n",
        "\n",
        "- Toma 25 imágenes del conjunto de entrenamiento usando .take(25).\n",
        "\n",
        "- Dibuja las imágenes en una cuadrícula de 5x5 usando matplotlib.\n",
        "\n",
        "**Asegúrate de:**\n",
        "\n",
        "- Convertir cada imagen a una matriz de 28x28.\n",
        "\n",
        "- Quitar los ejes (xticks, yticks) y la cuadrícula (grid).\n",
        "\n",
        "- Mostrar cada imagen en escala de grises (cmap=plt.cm.binary).\n",
        "\n",
        "- Colocar como título (o etiqueta) el número correspondiente a la clase.\n",
        "\n",
        "Forma esperada: un mosaico de 25 imágenes, cada una mostrando un dígito escrito a mano y su etiqueta correspondiente.\n"
      ],
      "metadata": {
        "id": "4SGOPKeVeCk1"
      },
      "id": "4SGOPKeVeCk1"
    },
    {
      "cell_type": "code",
      "source": [
        "#Codigo para mostrar imagenes del set, no es necesario ejecutarlo, solo imprime unos numeros :)\n",
        "# Para ver un batch (32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "imumzNcPeC6N"
      },
      "id": "imumzNcPeC6N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b9cc9489",
      "metadata": {
        "id": "b9cc9489"
      },
      "source": [
        "## Sección 4 — Construcción del modelo (Keras)\n",
        "\n",
        "**Objetivo**: Definir una red neuronal densa multiclase en Keras. Sin convoluciones ni dropout, ya que aún no lo hemos estudiado.\n",
        "\n",
        "**Requisitos mínimos**:\n",
        "- Usa `tf.keras.Sequential` (o Functional API) con *al menos* **2 capas ocultas**.\n",
        "- Las capas ocultas deben usar `activation='relu'`.\n",
        "- La capa de salida debe ser `Dense(10, activation='softmax')`.\n",
        "- Añadir al menos **una** técnica de regularización (BatchNormalization).\n",
        "- Pongale nombres a las capas\n",
        "-Usa add para adicoonar capas\n",
        "\n",
        "**Sugerencia de arquitectura (no obligatoria)**:\n",
        "- Input (784) → Dense(512, relu) → Dropout(0.2) → Dense(256, relu) → Dense(10, softmax)\n",
        "\n",
        "\n",
        "**Pista**: muestra el `model.summary()` al terminar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c1b37d",
      "metadata": {
        "id": "21c1b37d"
      },
      "outputs": [],
      "source": [
        "#Cree el Modelo\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Debes además** compilar el modelo con:\n",
        "- `optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)`\n",
        "- `loss=tf.keras.losses.SparseCategoricalCrossentropy()  Se usa cuando las etiquetas son enteros (0, 1, 2, ..., 9).\n",
        "- `metrics=['accuracy']`\n"
      ],
      "metadata": {
        "id": "XWv3_FtGRgHE"
      },
      "id": "XWv3_FtGRgHE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar el modelo\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pNmVI-k10aIb"
      },
      "id": "pNmVI-k10aIb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resumen de la arquitectura del modelo**\n",
        "\n",
        "Una vez que definas tu red neuronal, utiliza el método summary() para mostrar un resumen de la arquitectura del modelo.\n",
        "\n",
        "Aplica el método .summary() al objeto modelo.\n",
        "\n",
        "- Observa la salida en pantalla:\n",
        "\n",
        "- Nombre de cada capa.\n",
        "\n",
        "- Dimensión de salida de cada capa.\n",
        "\n",
        "- Cantidad de parámetros entrenables."
      ],
      "metadata": {
        "id": "buTA3V7nw4KU"
      },
      "id": "buTA3V7nw4KU"
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.summary()"
      ],
      "metadata": {
        "id": "LUAi0vx-xEhV"
      },
      "id": "LUAi0vx-xEhV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Número de ejemplos en MNIST**\n",
        "\n",
        "El objeto metadatos que devuelve tfds.load() contiene información sobre los subconjuntos del dataset.\n",
        "\n",
        "- Obtén el número de ejemplos en el conjunto de entrenamiento (train).\n",
        "\n",
        "- Obtén el número de ejemplos en el conjunto de pruebas (test).\n",
        "\n",
        "- Imprime ambos valores en pantalla.\n",
        "\n",
        "**Forma esperada:**\n",
        "\n",
        "Entrenamiento → 60000\n",
        "\n",
        "Pruebas → 10000\n",
        "\n",
        "**Pista:** usa la propiedad .splits[\"nombre\"].num_examples."
      ],
      "metadata": {
        "id": "By0E1ACmxWrt"
      },
      "id": "By0E1ACmxWrt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Número de ejemplos en train y test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Imprimir resultados\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_Iq0KENcR9dB"
      },
      "id": "_Iq0KENcR9dB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c6ebb852",
      "metadata": {
        "id": "c6ebb852"
      },
      "source": [
        "## Sección 5 — Entrenamiento\n",
        "\n",
        "**Objetivo**: Entrenar el modelo con validación y callbacks.\n",
        "\n",
        "**Debes hacer**:\n",
        "- Entrenar el modelo con `batch_size=32` y `epochs=100`.\n",
        "- Usa `validation_split=0.01`.\n",
        "- Implementa los callbacks:\n",
        "  - `EarlyStopping` con `monitor='val_loss'`, `patience=5`, `restore_best_weights=True`.\n",
        "- Guarda el historial de entrenamiento en una variable `history` o 'historial'.\n",
        "\n",
        "**Pista**: `model.fit(x_train, y_train, validation_split=0.1, callbacks=[...])`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Definición del tamaño de lote (batch size)**\n",
        "\n",
        "En el entrenamiento de redes neuronales, los datos se procesan en lotes (o batches) en lugar de pasar todas las muestras al mismo tiempo.\n",
        "\n",
        "**Define una variable llamada TAMANO_LOTE.**\n",
        "\n",
        "Asígnale el valor 32, que será el número de ejemplos que el modelo procesará en cada iteración.\n",
        "\n",
        "Explica brevemente en un comentario por qué es importante usar lotes en lugar de procesar todos los datos a la vez.\n",
        "\n",
        "**Pista: **el tamaño de lote es un hiperparámetro que afecta la velocidad de entrenamiento y el uso de memoria."
      ],
      "metadata": {
        "id": "zb5blYP6xr8-"
      },
      "id": "zb5blYP6xr8-"
    },
    {
      "cell_type": "code",
      "source": [
        "#Defina el numero de lotes\n",
        "\n"
      ],
      "metadata": {
        "id": "y437UzAIxsFe"
      },
      "id": "y437UzAIxsFe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Early Stopping en Keras**\n",
        "\n",
        "Durante el entrenamiento, un modelo puede dejar de mejorar y comenzar a sobreajustarse. Para evitarlo, se utiliza Early Stopping.\n",
        "\n",
        "Importa la clase EarlyStopping desde tensorflow.keras.callbacks.\n",
        "\n",
        "Crea un objeto llamado early_stopping que:\n",
        "\n",
        "Monitoree la métrica 'val_loss'.\n",
        "\n",
        "Tenga una paciencia (patience) de 5, lo que significa que el entrenamiento se detendrá si la pérdida de validación no mejora en 5 épocas consecutivas.\n",
        "\n",
        "Explica en un comentario cómo ayuda Early Stopping a prevenir el sobreajuste."
      ],
      "metadata": {
        "id": "IKbM_FnZy3uB"
      },
      "id": "IKbM_FnZy3uB"
    },
    {
      "cell_type": "code",
      "source": [
        "# defina la variable early_stopping\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YDZYk7lEy6jb"
      },
      "id": "YDZYk7lEy6jb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del modelo con validación**\n",
        "\n",
        "Ahora que ya has definido y compilado tu red neuronal, es momento de entrenarla.\n",
        "\n",
        "- Usa el método .fit() del objeto modelo.\n",
        "\n",
        "*Configura los siguientes parámetros:*\n",
        "\n",
        "- datos_entrenamiento como dataset de entrada.\n",
        "\n",
        "- epochs=100 como número máximo de épocas.\n",
        "\n",
        "- steps_per_epoch=math.ceil(num_datos_entrenamiento / TAMANO_LOTE) para definir el número de pasos por época.\n",
        "\n",
        "- callbacks=[early_stopping] para detener el entrenamiento si no hay mejora en la pérdida de validación.\n",
        "\n",
        "- verbose=1 para mostrar la barra de progreso durante el entrenamiento.\n",
        "\n",
        "- Guarda el resultado en una variable llamada historial."
      ],
      "metadata": {
        "id": "QR8l1dTcz-oh"
      },
      "id": "QR8l1dTcz-oh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d7126ec",
      "metadata": {
        "id": "7d7126ec"
      },
      "outputs": [],
      "source": [
        "# Cree la variable historial y entrene el modelo\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbed5c99",
      "metadata": {
        "id": "bbed5c99"
      },
      "source": [
        "## Sección 6 — Evaluación y análisis\n",
        "\n",
        "**Objetivo**: Evaluar el modelo en el conjunto de prueba y analizar errores.\n",
        "\n",
        "**Debes hacer**:\n",
        "1. Cargar (si existe) `best_model.h5` y evaluar en `x_test, y_test`, reportando `test_loss` y `test_accuracy`.\n",
        "2. Obtener predicciones (probabilidades y clases) sobre `x_test`.\n",
        "3. Calcular y mostrar la **matriz de confusión** y el **classification_report** usando `sklearn.metrics`.\n",
        "4. Mostrar 6 ejemplos donde el modelo se equivocó: la imagen, la etiqueta verdadera y la predicha.\n",
        "\n",
        "**Pista**: para la matriz de confusión usa `confusion_matrix(y_true, y_pred_classes)` (pasar etiquetas no one-hot).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Valuación del modelo en datos de prueba**\n",
        "\n",
        "Una vez entrenado tu modelo, evalúalo utilizando el conjunto de datos de prueba.\n",
        "\n",
        "Usa el método .evaluate() del modelo sobre datos_pruebas.\n",
        "\n",
        "Define el parámetro steps como math.ceil(num_datos_pruebas / TAMANO_LOTE) para recorrer todo el conjunto.\n",
        "\n",
        "Guarda los resultados en las variables perdidas y precision.\n",
        "\n",
        "Imprime en pantalla la precisión con 4 decimales usando:"
      ],
      "metadata": {
        "id": "AfsN8VRw3_ZH"
      },
      "id": "AfsN8VRw3_ZH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluación del modelo en el conjunto de prueba**\n",
        "\n",
        "Una vez finalizado el entrenamiento, es necesario evaluar el desempeño real del modelo sobre datos que no ha visto antes.\n",
        "\n",
        "- Usa el método .evaluate() sobre datos_pruebas.\n",
        "\n",
        "- Configura el parámetro steps como math.ceil(num_datos_pruebas / TAMANO_LOTE) para recorrer todas las muestras del conjunto.\n",
        "\n",
        "- Guarda los valores de salida en las variables perdidas y precision.\n",
        "\n",
        "- Muestra en consola la precisión obtenida con cuatro decimales utilizando:"
      ],
      "metadata": {
        "id": "tMjgmCFA4hbJ"
      },
      "id": "tMjgmCFA4hbJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo con los datos de pruebas\n",
        "\n"
      ],
      "metadata": {
        "id": "sFsrEsZ03_mZ"
      },
      "id": "sFsrEsZ03_mZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Guardar el modelo entrenado**\n",
        "\n",
        "Una vez entrenado y evaluado, guarda tu modelo para poder cargarlo más adelante sin necesidad de volver a entrenarlo.\n",
        "\n",
        "Utiliza el método .save() de Keras para guardar el modelo en el formato nativo de Keras con la extensión .keras."
      ],
      "metadata": {
        "id": "5ZzjNgBD4vRh"
      },
      "id": "5ZzjNgBD4vRh"
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo en el formato  de Keras\n",
        "\n"
      ],
      "metadata": {
        "id": "YqmDfjii4vfo"
      },
      "id": "YqmDfjii4vfo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "293b4d73",
      "metadata": {
        "id": "293b4d73"
      },
      "source": [
        "## Sección 7 — Curvas de entrenamiento\n",
        "\n",
        "**Objetivo**: Graficar la pérdida y la precisión durante el entrenamiento.\n",
        "\n",
        "**Debes hacer**:\n",
        "- Usar `history.history` para graficar:\n",
        "  - `loss` vs `val_loss`\n",
        "  - `accuracy` vs `val_accuracy`\n",
        "\n",
        "**Pista**: usa `matplotlib` y añade títulos, leyenda y ejes correctamente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d291d0",
      "metadata": {
        "id": "20d291d0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Obtener los valores del historial\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "# Gráfica de accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Gráfica de pérdida\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sección 9 — Evaluación del modelo con imágenes externas\n",
        "\n",
        "Usa las siguientes imágenes de dígitos manuscritos:\n",
        "\n",
        "Número 3\n",
        "\n",
        "Número 6\n",
        "\n",
        "Descarga cada imagen desde la URL.\n",
        "\n",
        "Conviértela a escala de grises y redimensiona a 28×28 píxeles.\n",
        "\n",
        "Normaliza los valores de los píxeles (0–255 → 0–1).\n",
        "\n",
        "Ajusta la forma a (1, 28, 28, 1).\n",
        "\n",
        "Muestra la imagen procesada y la predicción que hace el modelo."
      ],
      "metadata": {
        "id": "MLR5PG7L5aAr"
      },
      "id": "MLR5PG7L5aAr"
    },
    {
      "cell_type": "code",
      "source": [
        "#Solo ejecute\n",
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Función para cargar y preparar una imagen externa\n",
        "def preparar_imagen(url):\n",
        "    # Descargar imagen desde la URL\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content)).convert(\"L\")  # escala de grises\n",
        "\n",
        "    # Redimensionar a 28x28\n",
        "    img = img.resize((28, 28))\n",
        "\n",
        "    # Convertir a array y normalizar\n",
        "    img_array = np.array(img) / 255.0\n",
        "\n",
        "    # Cambiar forma a (1, 28, 28, 1)\n",
        "    img_array = np.expand_dims(img_array, axis=(0, -1))\n",
        "\n",
        "    return img_array, img\n",
        "\n",
        "# URLs de las imágenes\n",
        "urls = [\n",
        "    \"https://raw.githubusercontent.com/adiacla/bigdata/refs/heads/master/numero3.jpg\",\n",
        "    \"https://raw.githubusercontent.com/adiacla/bigdata/refs/heads/master/numero2.jpg\"\n",
        "]\n",
        "\n",
        "for url in urls:\n",
        "    procesada, original = preparar_imagen(url)\n",
        "\n",
        "    # Mostrar imagen original\n",
        "    plt.imshow(original, cmap=\"gray\")\n",
        "    plt.title(\"Imagen original\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # Predicción\n",
        "    prediccion = modelo.predict(procesada)\n",
        "    clase_predicha = np.argmax(prediccion)\n",
        "\n",
        "    print(\"URL:\", url)\n",
        "    print(\"El modelo predice que es el número:\", clase_predicha)\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "QHuAvH9161iN"
      },
      "id": "QHuAvH9161iN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a9d75193",
      "metadata": {
        "id": "a9d75193"
      },
      "source": [
        "---\n",
        "\n",
        "## Entrega y rúbrica de evaluación\n",
        "\n",
        "**Rúbrica (100 puntos)**:\n",
        "- Sección 1: Importaciones y versiones — 5 pts\n",
        "- Sección 2: Carga de datos y verificación — 10 pts\n",
        "- Sección 3: Preprocesamiento correcto — 15 pts\n",
        "- Sección 4: Arquitectura bien definida y compilación — 20 pts\n",
        "- Sección 5: Entrenamiento correcto con callbacks — 20 pts\n",
        "- Sección 6: Evaluación y análisis (matriz de confusión + ejemplos) — 20 pts\n",
        "- Sección 7: Gráficas de entrenamiento — 5 pts\n",
        "- Sección 8: Respuesta teórica — 5 pts\n",
        "\n",
        "**Formato de entrega**: sube este notebook con todas las celdas de código completadas y `best_model.h5` (si se generó) en el mismo directorio.\n",
        "\n",
        "Buena suerte 😊\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}